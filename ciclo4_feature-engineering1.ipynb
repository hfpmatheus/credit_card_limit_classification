{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.0 IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mathe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import warnings\n",
    "import sweetviz\n",
    "import IPython\n",
    "import pickle\n",
    "\n",
    "import pandas            as pd\n",
    "import numpy             as np\n",
    "import lightgbm          as lgb\n",
    "import xgboost           as xgb\n",
    "import seaborn           as sns\n",
    "\n",
    "from category_encoders       import TargetEncoder\n",
    "from sklearn.preprocessing   import OneHotEncoder\n",
    "from sklearn.ensemble        import ExtraTreesClassifier, RandomForestClassifier, StackingClassifier\n",
    "from sklearn.linear_model    import LogisticRegression\n",
    "from sklearn.neighbors       import KNeighborsClassifier\n",
    "from sklearn.naive_bayes     import GaussianNB\n",
    "from scipy                   import stats\n",
    "from unidecode               import unidecode\n",
    "from catboost                import CatBoostClassifier\n",
    "from skopt                   import gp_minimize\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from imblearn                import over_sampling\n",
    "from sklearn                 import svm\n",
    "from sklearn.preprocessing   import RobustScaler, MinMaxScaler\n",
    "from sklearn.tree            import DecisionTreeClassifier\n",
    "\n",
    "from sklearn                 import model_selection   as ms\n",
    "from sklearn                 import metrics           as m\n",
    "from matplotlib              import pyplot            as plt\n",
    "from imblearn                import combine           as co\n",
    "from sklearn                 import manifold          as mn\n",
    "from sklearn                 import cluster           as c\n",
    "from yellowbrick.cluster     import KElbowVisualizer, SilhouetteVisualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 AUX FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "def ml_error( model_name, ytest, yhat ):\n",
    "    f1 = m.f1_score( ytest, yhat )\n",
    "\n",
    "    return pd.DataFrame( {'Model name': model_name,\n",
    "                          'F1': f1 }, index=[0] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 READ DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 DATA DESCRIPTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df users rows: 9500\n",
      "df users columns: 17\n"
     ]
    }
   ],
   "source": [
    "print( f\"df users rows: {df.shape[0]}\" )\n",
    "print( f\"df users columns: {df.shape[1]}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "\n",
    "# df2['percentual_endividamento_saldo'] = df2.apply( lambda x: x['divida_atual'] / x['saldo_atual'], axis=1 )\n",
    "# df2['percentual_endividamento_renda'] = df2.apply( lambda x: x['divida_atual'] / x['renda_anual'], axis=1 )\n",
    "df2['renda_anual'] = df2['renda_anual'].apply( lambda x: x/12 )\n",
    "df2['divida_atual'] = df2['divida_atual'].apply( lambda x: x/12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2['faixa_atraso_dt_venc'] = df2['dias_atraso_dt_venc'].apply( lambda x: '0' if x <= 0 else \n",
    "#                                                                           '1 - 10' if x >= 1 and x <= 10 else\n",
    "#                                                                           '11 - 20' if x >= 11 and x <= 20 else\n",
    "#                                                                           '21 - 30' if x >= 21 and x <= 30 else\n",
    "#                                                                           '31 - 40' if x >= 31 and x <= 40 else\n",
    "#                                                                           '41 - 50' if x >= 41 and x <= 50 else\n",
    "#                                                                           '51 - 60' if x >= 51 and x <= 60 else\n",
    "#                                                                           '60 +' if x > 60 else x)\n",
    "\n",
    "df2['faixa_num_emprestimos'] = df2['num_emprestimos'].apply( lambda x: '0' if x <= 0 else \n",
    "                                                                       '1 - 3' if x >= 1 and x <= 3 else\n",
    "                                                                       '4 - 6' if x >= 4 and x <= 6 else\n",
    "                                                                       '6 - 9' if x >= 6 and x <= 9 else\n",
    "                                                                       '10 +' if x > 10 else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 DATA FILTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.copy()\n",
    "\n",
    "df3['idade'] = df3['idade'].apply( lambda x: int(str(x)[:2]) if x>100 else x )\n",
    "df3['taxa_juros'] = df3['taxa_juros'].apply( lambda x: int(str(x)[:2]) if x>100 else x )\n",
    "\n",
    "mediana_cartao = df3['num_cartoes_credito'].median()\n",
    "df3['num_cartoes_credito'] = df3['num_cartoes_credito'].apply( lambda x: mediana_cartao if x>100 else x )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0 EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3.copy()\n",
    "\n",
    "# sweetviz report\n",
    "# report = sweetviz.analyze( df, \"limite_adicional\" )\n",
    "# report.show_html()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.0 DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df3.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min Max Scaler\n",
    "mms = MinMaxScaler()\n",
    "\n",
    "df5['idade'] = mms.fit_transform( df5[['idade']].values )\n",
    "pickle.dump( mms, open( 'encoders/idade_scaler', 'wb') )\n",
    "\n",
    "# Robust Scaler\n",
    "rs = RobustScaler()\n",
    "\n",
    "df5['saldo_atual'] = rs.fit_transform( df5[['saldo_atual']].values )\n",
    "pickle.dump( rs, open( 'encoders/saldo_atual_scaler', 'wb') )\n",
    "\n",
    "df5['divida_atual'] = rs.fit_transform( df5[['divida_atual']].values )\n",
    "pickle.dump( rs, open( 'encoders/divida_atual_scaler', 'wb') )\n",
    "\n",
    "df5['renda_anual'] = rs.fit_transform( df5[['renda_anual']].values )\n",
    "pickle.dump( rs, open( 'encoders/renda_anual_scaler', 'wb') )\n",
    "\n",
    "df5['valor_em_investimentos'] = rs.fit_transform( df5[['valor_em_investimentos']].values )\n",
    "pickle.dump( rs, open( 'encoders/valor_em_investimentos_scaler', 'wb') )\n",
    "\n",
    "df5['taxa_utilizacao_credito'] = rs.fit_transform( df5[['taxa_utilizacao_credito']].values )\n",
    "pickle.dump( rs, open( 'encoders/taxa_utilizacao_credito_scaler', 'wb') )\n",
    "\n",
    "df5['num_emprestimos'] = rs.fit_transform( df5[['num_emprestimos']].values )\n",
    "pickle.dump( rs, open( 'encoders/num_emprestimos_scaler', 'wb') )\n",
    "\n",
    "df5['num_contas_bancarias'] = rs.fit_transform( df5[['num_contas_bancarias']].values )\n",
    "pickle.dump( rs, open( 'encoders/num_contas_bancarias_scaler', 'wb') )\n",
    "\n",
    "df5['num_cartoes_credito'] = rs.fit_transform( df5[['num_cartoes_credito']].values )\n",
    "pickle.dump( rs, open( 'encoders/num_cartoes_credito_scaler', 'wb') )\n",
    "\n",
    "df5['dias_atraso_dt_venc'] = rs.fit_transform( df5[['dias_atraso_dt_venc']].values )\n",
    "pickle.dump( rs, open( 'encoders/dias_atraso_dt_venc_scaler', 'wb') )\n",
    "\n",
    "df5['num_pgtos_atrasados'] = rs.fit_transform( df5[['num_pgtos_atrasados']].values )\n",
    "pickle.dump( rs, open( 'encoders/num_pgtos_atrasados_scaler', 'wb') )\n",
    "\n",
    "df5['num_consultas_credito'] = rs.fit_transform( df5[['num_consultas_credito']].values )\n",
    "pickle.dump( rs, open( 'encoders/num_consultas_credito_scaler', 'wb') )\n",
    "\n",
    "df5['taxa_juros'] = rs.fit_transform( df5[['taxa_juros']].values )\n",
    "pickle.dump( rs, open( 'encoders/taxa_juros_scaler', 'wb') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limite adicional\n",
    "df5['limite_adicional'] = df5['limite_adicional'].apply( lambda x: 0 if x == 'Negar' else 1 )\n",
    "\n",
    "# target encoder\n",
    "te = TargetEncoder()\n",
    "\n",
    "df5['investe_exterior'] = te.fit_transform( df5['investe_exterior'], df5['limite_adicional'] )\n",
    "pickle.dump( te, open( 'encoders/investe_exterior_encoding', 'wb' ) )\n",
    "\n",
    "df5['pessoa_polit_exp'] = te.fit_transform( df5['pessoa_polit_exp'], df5['limite_adicional'] )\n",
    "pickle.dump( te, open( 'encoders/pessoa_polit_exp_encoding', 'wb' ) )\n",
    "\n",
    "df5['faixa_num_emprestimos'] = te.fit_transform( df5['faixa_num_emprestimos'], df5['limite_adicional'] )\n",
    "pickle.dump( te, open( 'encoders/faixa_num_emprestimos_encoding', 'wb' ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resampling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = df5.drop( columns='limite_adicional')\n",
    "df_target = df5['limite_adicional'].copy()\n",
    "\n",
    "# # define\n",
    "# os = over_sampling.SMOTE( random_state=32, n_jobs=-1 )\n",
    "\n",
    "# # apply\n",
    "# features_smt, target_smt = os.fit_resample( df_features, df_target )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define\n",
    "smt = co.SMOTETomek( random_state=32, n_jobs=-1 )\n",
    "\n",
    "# apply\n",
    "features_smt, target_smt = smt.fit_resample( df_features, df_target )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got scalar array instead:\narray=nan.\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mathe\\Repos_ComunidadeDS\\hackdays_3\\ciclo4_feature-engineering1.ipynb Célula: 27\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mathe/Repos_ComunidadeDS/hackdays_3/ciclo4_feature-engineering1.ipynb#Y145sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m kmeans \u001b[39m=\u001b[39m c\u001b[39m.\u001b[39mKMeans( n_clusters\u001b[39m=\u001b[39mk )\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mathe/Repos_ComunidadeDS/hackdays_3/ciclo4_feature-engineering1.ipynb#Y145sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# model training\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/mathe/Repos_ComunidadeDS/hackdays_3/ciclo4_feature-engineering1.ipynb#Y145sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m kmeans\u001b[39m.\u001b[39;49mfit( df3 )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mathe/Repos_ComunidadeDS/hackdays_3/ciclo4_feature-engineering1.ipynb#Y145sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# model predict\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mathe/Repos_ComunidadeDS/hackdays_3/ciclo4_feature-engineering1.ipynb#Y145sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m labels \u001b[39m=\u001b[39m kmeans\u001b[39m.\u001b[39mpredict( df3 )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:1367\u001b[0m, in \u001b[0;36mKMeans.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1341\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   1342\u001b[0m     \u001b[39m\"\"\"Compute k-means clustering.\u001b[39;00m\n\u001b[0;32m   1343\u001b[0m \n\u001b[0;32m   1344\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1365\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1366\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1367\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m   1368\u001b[0m         X,\n\u001b[0;32m   1369\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1370\u001b[0m         dtype\u001b[39m=\u001b[39;49m[np\u001b[39m.\u001b[39;49mfloat64, np\u001b[39m.\u001b[39;49mfloat32],\n\u001b[0;32m   1371\u001b[0m         order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1372\u001b[0m         copy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy_x,\n\u001b[0;32m   1373\u001b[0m         accept_large_sparse\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m   1374\u001b[0m     )\n\u001b[0;32m   1376\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_params(X)\n\u001b[0;32m   1377\u001b[0m     random_state \u001b[39m=\u001b[39m check_random_state(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_state)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\base.py:577\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    575\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    576\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 577\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    578\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[0;32m    579\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\utils\\validation.py:871\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[39mif\u001b[39;00m ensure_2d:\n\u001b[0;32m    869\u001b[0m     \u001b[39m# If input is scalar raise error\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[39mif\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 871\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    872\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got scalar array instead:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39marray=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    873\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    874\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    875\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mif it contains a single sample.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    876\u001b[0m         )\n\u001b[0;32m    877\u001b[0m     \u001b[39m# If input is 1D raise error\u001b[39;00m\n\u001b[0;32m    878\u001b[0m     \u001b[39mif\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got scalar array instead:\narray=nan.\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "clusters = [ 2, 3 , 4, 5, 10, 15, 20 ]\n",
    "kmeans_list = []\n",
    "\n",
    "for k in clusters:\n",
    "    # model definition\n",
    "    kmeans = c.KMeans( n_clusters=k )\n",
    "\n",
    "    # model training\n",
    "    kmeans.fit( df3 )\n",
    "\n",
    "    # model predict\n",
    "    labels = kmeans.predict( df3 )\n",
    "\n",
    "    # model performance\n",
    "    silhouette = m.silhouette_score( df3, labels, metric='euclidean' )\n",
    "    kmeans_list.append( silhouette )\n",
    "\n",
    "# model definition\n",
    "k = 15\n",
    "kmeans = c.KMeans( init='random', n_clusters=k, n_init=10, max_iter=300, random_state=42 )\n",
    "\n",
    "# model training\n",
    "kmeans.fit( df3 )\n",
    "\n",
    "# clustering\n",
    "labels = kmeans.labels_\n",
    "\n",
    "df3['cluster'] = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.0 FEATURE SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ExtraTreesClassifier(n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExtraTreesClassifier</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesClassifier(n_jobs=-1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "ExtraTreesClassifier(n_jobs=-1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model\n",
    "forest = ExtraTreesClassifier( n_jobs=-1 )\n",
    "\n",
    "# training\n",
    "X = df5.drop( columns=['limite_adicional'])\n",
    "Y = df5['limite_adicional'].values\n",
    "\n",
    "x_train_fselection, x_val, y_train_fselection, y_val = ms.train_test_split( X, Y, test_size=0.5, random_state=42 )\n",
    "\n",
    "forest.fit( x_train_fselection, y_train_fselection )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Ranking:\n",
      "\n",
      "                   feature  importance\n",
      "0      dias_atraso_dt_venc    0.128406\n",
      "0               taxa_juros    0.105413\n",
      "0      num_cartoes_credito    0.102709\n",
      "0      num_pgtos_atrasados    0.067895\n",
      "0             divida_atual    0.066930\n",
      "0     num_contas_bancarias    0.060667\n",
      "0              saldo_atual    0.059139\n",
      "0    num_consultas_credito    0.053871\n",
      "0                    idade    0.052453\n",
      "0  taxa_utilizacao_credito    0.050806\n",
      "0              renda_anual    0.050502\n",
      "0   valor_em_investimentos    0.050304\n",
      "0               id_cliente    0.050183\n",
      "0    faixa_num_emprestimos    0.044710\n",
      "0          num_emprestimos    0.033093\n",
      "0         investe_exterior    0.014357\n",
      "0         pessoa_polit_exp    0.008563\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "importances = forest.feature_importances_\n",
    "std = np.std( [tree.feature_importances_ for tree in forest.estimators_], axis=0 )\n",
    "indices = np.argsort( importances )[::-1]\n",
    "\n",
    "# print the feature ranking\n",
    "df = pd.DataFrame()\n",
    "\n",
    "print( 'Feature Ranking:\\n' )\n",
    "for i, j in zip( x_train_fselection,forest.feature_importances_ ):\n",
    "    aux = pd.DataFrame( {'feature': i, 'importance': j}, index=[0] )\n",
    "    df = pd.concat( [df, aux], axis=0 )\n",
    "    \n",
    "print( df.sort_values( 'importance', ascending=False ) ) \n",
    "\n",
    "# plot the impurity-based feature importances of the forest\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title( 'Feature importances' )\n",
    "plt.bar( range( x_train_fselection.shape[1] ), importances[indices], color='r', yerr=std[indices], align='center' )\n",
    "plt.xticks( range(x_train_fselection.shape[1]), indices )\n",
    "plt.xlim( [-1, x_train_fselection.shape[1]] )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.0 MACHINE LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features_smt.drop( columns = ['id_cliente'] )\n",
    "Y = target_smt.copy()\n",
    "\n",
    "X_train, X_val, y_train, y_val = ms.train_test_split( X, Y, test_size=0.2, random_state=42 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model name</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.935343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model name        F1\n",
       "0   LightGBM  0.935343"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model\n",
    "model_lgb = lgb.LGBMClassifier( n_estimators=1428, max_depth=20, learning_rate=0.03159717592160721, num_leaves=128, \n",
    "min_child_samples=1, subsample=1.0, colsample_bytree=1.0, n_jobs=-1, random_state=42, subsample_freq=1 ).fit( X_train, y_train )\n",
    "# model_lgb = lgb.LGBMClassifier( n_jobs=-1 ).fit( X_train, y_train )\n",
    "pickle.dump( model_lgb, open( 'model/model_lgb.pkl', 'wb' ) )\n",
    "\n",
    "# prediction\n",
    "yhat_lgb = model_lgb.predict( X_val )\n",
    "\n",
    "# performance\n",
    "model_lgb_results = ml_error( 'LightGBM',  y_val, yhat_lgb )\n",
    "model_lgb_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.1 Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # cross validation\n",
    "# kfold = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "# cv = cross_val_score(model_lgb, X, Y, scoring='f1', cv=kfold, n_jobs=-1, error_score='raise' )\n",
    "# print( \"{} +/- {}\".format( np.mean(cv), np.std(cv)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model name</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.930839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model name        F1\n",
       "0    XGBoost  0.930839"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model\n",
    "model_xgb = xgb.XGBClassifier( n_jobs=-1 ).fit( X_train, y_train )\n",
    "\n",
    "# prediction\n",
    "yhat_xgb = model_xgb.predict( X_val )\n",
    "\n",
    "# performance\n",
    "model_xgb_results = ml_error( 'XGBoost',  y_val, yhat_xgb )\n",
    "model_xgb_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.1 Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # cross validation\n",
    "# kfold = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "# cv = cross_val_score(model_xgb, X, Y, scoring='f1', cv=kfold, n_jobs=-1, error_score='raise' )\n",
    "# print( \"{} +/- {}\".format( np.mean(cv), np.std(cv)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mathe\\Repos_ComunidadeDS\\hackdays_3\\ciclo4_feature-engineering1.ipynb Célula: 43\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mathe/Repos_ComunidadeDS/hackdays_3/ciclo4_feature-engineering1.ipynb#X54sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# model\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/mathe/Repos_ComunidadeDS/hackdays_3/ciclo4_feature-engineering1.ipynb#X54sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model_cb \u001b[39m=\u001b[39m CatBoostClassifier( verbose\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m )\u001b[39m.\u001b[39;49mfit( X_train, y_train )\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mathe/Repos_ComunidadeDS/hackdays_3/ciclo4_feature-engineering1.ipynb#X54sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# prediction\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mathe/Repos_ComunidadeDS/hackdays_3/ciclo4_feature-engineering1.ipynb#X54sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m yhat_cb \u001b[39m=\u001b[39m model_cb\u001b[39m.\u001b[39mpredict( X_val )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\catboost\\core.py:5128\u001b[0m, in \u001b[0;36mCatBoostClassifier.fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   5125\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m params:\n\u001b[0;32m   5126\u001b[0m     CatBoostClassifier\u001b[39m.\u001b[39m_check_is_compatible_loss(params[\u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m-> 5128\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, cat_features, text_features, embedding_features, \u001b[39mNone\u001b[39;49;00m, sample_weight, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, baseline, use_best_model,\n\u001b[0;32m   5129\u001b[0m           eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period,\n\u001b[0;32m   5130\u001b[0m           silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n\u001b[0;32m   5131\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\catboost\\core.py:2355\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   2351\u001b[0m allow_clear_pool \u001b[39m=\u001b[39m train_params[\u001b[39m\"\u001b[39m\u001b[39mallow_clear_pool\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   2353\u001b[0m \u001b[39mwith\u001b[39;00m log_fixup(log_cout, log_cerr), \\\n\u001b[0;32m   2354\u001b[0m     plot_wrapper(plot, plot_file, \u001b[39m'\u001b[39m\u001b[39mTraining plots\u001b[39m\u001b[39m'\u001b[39m, [_get_train_dir(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_params())]):\n\u001b[1;32m-> 2355\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train(\n\u001b[0;32m   2356\u001b[0m         train_pool,\n\u001b[0;32m   2357\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39meval_sets\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m   2358\u001b[0m         params,\n\u001b[0;32m   2359\u001b[0m         allow_clear_pool,\n\u001b[0;32m   2360\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39minit_model\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[0;32m   2361\u001b[0m     )\n\u001b[0;32m   2363\u001b[0m \u001b[39m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[0;32m   2364\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_object\u001b[39m.\u001b[39m_get_loss_function_name()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\catboost\\core.py:1759\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[1;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[0;32m   1758\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_train\u001b[39m(\u001b[39mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[1;32m-> 1759\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_object\u001b[39m.\u001b[39;49m_train(train_pool, test_pool, params, allow_clear_pool, init_model\u001b[39m.\u001b[39;49m_object \u001b[39mif\u001b[39;49;00m init_model \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m   1760\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_trained_model_attributes()\n",
      "File \u001b[1;32m_catboost.pyx:4622\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_catboost.pyx:4671\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model\n",
    "model_cb = CatBoostClassifier( verbose=False ).fit( X_train, y_train )\n",
    "\n",
    "# prediction\n",
    "yhat_cb = model_cb.predict( X_val )\n",
    "\n",
    "# performance\n",
    "model_cb_results = ml_error( 'CatBoost',  y_val, yhat_cb)\n",
    "model_cb_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.1 Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4 Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model name</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.930797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model name        F1\n",
       "0   CatBoost  0.930797"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model\n",
    "model_rf = RandomForestClassifier().fit( X_train, y_train )\n",
    "\n",
    "# prediction\n",
    "yhat_rf = model_rf.predict( X_val )\n",
    "\n",
    "# performance\n",
    "model_rf_results = ml_error( 'CatBoost',  y_val, yhat_rf)\n",
    "model_rf_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5 Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model name</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.94529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model name       F1\n",
       "0   CatBoost  0.94529"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model\n",
    "model_et = ExtraTreesClassifier().fit( X_train, y_train )\n",
    "\n",
    "# prediction\n",
    "yhat_et = model_et.predict( X_val )\n",
    "\n",
    "# performance\n",
    "model_et_results = ml_error( 'CatBoost',  y_val, yhat_et)\n",
    "model_et_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.6 KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model name</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.864686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model name        F1\n",
       "0        KNN  0.864686"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model\n",
    "model_knn = KNeighborsClassifier().fit( X_train, y_train )\n",
    "\n",
    "# prediction\n",
    "yhat_knn = model_knn.predict( X_val )\n",
    "\n",
    "# performance\n",
    "model_knn_results = ml_error( 'KNN',  y_val, yhat_knn)\n",
    "model_knn_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.7 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model name</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.849324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model name        F1\n",
       "0   Logistic  0.849324"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model\n",
    "model_logistic = LogisticRegression().fit( X_train, y_train )\n",
    "\n",
    "# prediction\n",
    "yhat_logistic = model_logistic.predict( X_val )\n",
    "\n",
    "# performance\n",
    "model_logistic_results = ml_error( 'Logistic',  y_val, yhat_logistic)\n",
    "model_logistic_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.8 Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model name</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.799888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model name        F1\n",
       "0   Logistic  0.799888"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model\n",
    "model_gaussian = GaussianNB().fit( X_train, y_train )\n",
    "\n",
    "# prediction\n",
    "yhat_gaussian = model_gaussian.predict( X_val )\n",
    "\n",
    "# performance\n",
    "model_gaussian_results = ml_error( 'Logistic',  y_val, yhat_gaussian )\n",
    "model_gaussian_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.9 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model name</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.844947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model name        F1\n",
       "0   Logistic  0.844947"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model\n",
    "model_svm = svm.SVC().fit( X_train, y_train )\n",
    "\n",
    "# prediction\n",
    "yhat_svm = model_svm.predict( X_val )\n",
    "\n",
    "# performance\n",
    "model_svm_results = ml_error( 'Logistic',  y_val, yhat_svm )\n",
    "model_svm_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.11 Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model name</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.89281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model name       F1\n",
       "0  Decision Tree  0.89281"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model\n",
    "model_dt = DecisionTreeClassifier().fit( X_train, y_train )\n",
    "\n",
    "# prediction\n",
    "yhat_dt = model_dt.predict( X_val )\n",
    "\n",
    "# performance\n",
    "model_dt_results = ml_error( 'Decision Tree',  y_val, yhat_dt )\n",
    "model_dt_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.10 Stacking Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "estimators_list = [ ('lgbm', model_lgb), ('xgboost', model_xgb), ('catboost', model_cb), ('random forest', model_rf ), ('extra trees', model_et),\n",
    "('decision tree', model_dt) ]\n",
    "#('knn', model_knn), ('logistic regression', model_logistic), ('gaussian', model_gaussian), ('svm', model_svm), \n",
    "\n",
    "# Build stack model\n",
    "stack_model = StackingClassifier( estimators = estimators_list, n_jobs=-1, verbose=True ).fit( X_train, y_train )\n",
    "pickle.dump( stack_model, open( 'model/model_stack.pkl', 'wb' ) )\n",
    "\n",
    "# prediction\n",
    "yhat_stack = stack_model.predict( X_val )\n",
    "\n",
    "# performance\n",
    "stack_model_results = ml_error( 'Stacking', y_val, yhat_stack )\n",
    "stack_model_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.7.1 Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # cross validation\n",
    "# kfold = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "# cv = cross_val_score(stack_model, X, Y, scoring='f1', cv=kfold, n_jobs=-1, error_score='raise' )\n",
    "# print( \"{} +/- {}\".format( np.mean(cv), np.std(cv)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.0 Bayesian Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_space = [(100, 1500), #name = 'n_estimators'), \n",
    "#                 (1, 20), #name = 'max_depth'), \n",
    "#                 (0.001, 0.1, 'log-uniform'),#, name = 'learning_rate'),\n",
    "#                 (2, 128), #name = 'num_leaves'),\n",
    "#                 (1, 100), #name = 'min_child_samples'),\n",
    "#                 (0.05, 1.0), #name = 'subsample'),\n",
    "#                 (0.15, 1.0) #name = 'colsample_bytree')]\n",
    "# ]\n",
    "\n",
    "# def treinar_modelo( params ):\n",
    "#     n_estimators = params[0]\n",
    "#     max_depth = params[1]\n",
    "#     learning_rate = params[2]\n",
    "#     num_leaves = params[3]\n",
    "#     min_child_samples = params[4]\n",
    "#     subsample = params[5]\n",
    "#     colsample_bytree = params[6]\n",
    "\n",
    "#     print(params, '\\n')\n",
    "\n",
    "#     lgbm_model = lgb.LGBMClassifier( learning_rate = learning_rate, num_leaves=num_leaves, n_estimators=n_estimators, max_depth=max_depth, min_child_samples=min_child_samples, subsample=subsample, colsample_bytree=colsample_bytree, n_jobs=-1, random_state=42, subsample_freq=1)\n",
    "#     lgbm_model.fit( X_train, y_train )\n",
    "\n",
    "#     yhat_lgb = lgbm_model.predict( X_val )\n",
    "\n",
    "#     return -m.f1_score( y_val, yhat_lgb )\n",
    "\n",
    "# result = gp_minimize( treinar_modelo, search_space, n_calls = 200, n_initial_points = 10, verbose=True, n_jobs=-1, random_state= 42 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_space = [(100, 1500), #name = 'n_estimators'), \n",
    "#                 (1, 20), #name = 'max_depth'), \n",
    "#                 (0.001, 0.1, 'log-uniform'),#, name = 'learning_rate'),\n",
    "#                 (2, 128), #name = 'num_leaves'),\n",
    "#                 (1, 100), #name = 'min_child_samples'),\n",
    "#                 (0.05, 1.0), #name = 'subsample'),\n",
    "#                 (0.15, 1.0) #name = 'colsample_bytree')]\n",
    "# ]\n",
    "\n",
    "# def treinar_modelo( params ):\n",
    "#     n_estimators = params[0]\n",
    "#     max_depth = params[1]\n",
    "#     learning_rate = params[2]\n",
    "#     num_leaves = params[3]\n",
    "#     min_child_samples = params[4]\n",
    "#     subsample = params[5]\n",
    "#     colsample_bytree = params[6]\n",
    "\n",
    "#     print(params, '\\n')\n",
    "\n",
    "#     xgb_model = xgb.XGBClassifier( learning_rate = learning_rate, num_leaves=num_leaves, n_estimators=n_estimators, max_depth=max_depth, min_child_samples=min_child_samples, subsample=subsample, colsample_bytree=colsample_bytree, n_jobs=-1, random_state=42, subsample_freq=1)\n",
    "#     xgb_model.fit( X_train, y_train )\n",
    "\n",
    "#     yhat_xgb = xgb_model.predict( X_val )\n",
    "\n",
    "#     return -m.f1_score( y_val, yhat_xgb )\n",
    "\n",
    "# result = gp_minimize( treinar_modelo, search_space, n_calls = 200, n_initial_points = 10, verbose=True, n_jobs=-1, random_state= 42 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3 CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_space = [(6, 10), #depth\n",
    "#                 (0.01, 0.1), #learning rate\n",
    "#                 (100, 200), #iterations\n",
    "# ]\n",
    "\n",
    "# def treinar_modelo( params ):\n",
    "#     depth = params[0]\n",
    "#     learning_rate = params[1]\n",
    "#     iterations = params[2]\n",
    "\n",
    "#     print(params, '\\n' )\n",
    "\n",
    "#     catboost_model = CatBoostClassifier( depth = depth, learning_rate=learning_rate, iterations=iterations, verbose=False )\n",
    "#     catboost_model.fit( X_train, y_train )\n",
    "\n",
    "#     yhat_catboost = catboost_model.predict( X_val )\n",
    "\n",
    "#     return -m.f1_score( y_val, yhat_catboost )\n",
    "\n",
    "# result = gp_minimize( treinar_modelo, search_space, n_calls = 100, n_initial_points = 10, verbose=True, n_jobs=-1, random_state= 42 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.4 Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_space = [(100, 1500), #name = 'n_estimators'), \n",
    "#                 (1, 20), #name = 'max_depth'), \n",
    "#                 (0.001, 0.1, 'log-uniform'),#, name = 'learning_rate'),\n",
    "#                 (2, 128), #name = 'num_leaves'),\n",
    "#                 (1, 100), #name = 'min_child_samples'),\n",
    "#                 (0.05, 1.0), #name = 'subsample'),\n",
    "#                 (0.15, 1.0) #name = 'colsample_bytree')]\n",
    "# ]\n",
    "\n",
    "# def treinar_modelo( params ):\n",
    "#     n_estimators = params[0]\n",
    "#     max_depth = params[1]\n",
    "#     learning_rate = params[2]\n",
    "#     num_leaves = params[3]\n",
    "#     min_child_samples = params[4]\n",
    "#     subsample = params[5]\n",
    "#     colsample_bytree = params[6]\n",
    "\n",
    "#     print(params, '\\n')\n",
    "\n",
    "#     model_rf = RandomForestClassifier( learning_rate = learning_rate, num_leaves=num_leaves, n_estimators=n_estimators, max_depth=max_depth, min_child_samples=min_child_samples, subsample=subsample, colsample_bytree=colsample_bytree, n_jobs=-1, random_state=42, subsample_freq=1)\n",
    "#     model_rf.fit( X_train, y_train )\n",
    "\n",
    "#     yhat_rf = model_rf.predict( X_val )\n",
    "\n",
    "#     return -m.f1_score( y_val, yhat_rf )\n",
    "\n",
    "# result = gp_minimize( treinar_modelo, search_space, n_calls = 200, n_initial_points = 10, verbose=True, n_jobs=-1, random_state= 42 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.5 Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_space = [(100, 1500), #name = 'n_estimators'), \n",
    "#                 (1, 20), #name = 'max_depth'), \n",
    "#                 (0.001, 0.1, 'log-uniform'),#, name = 'learning_rate'),\n",
    "#                 (2, 128), #name = 'num_leaves'),\n",
    "#                 (1, 100), #name = 'min_child_samples'),\n",
    "#                 (0.05, 1.0), #name = 'subsample'),\n",
    "#                 (0.15, 1.0) #name = 'colsample_bytree')]\n",
    "# ]\n",
    "\n",
    "# def treinar_modelo( params ):\n",
    "#     n_estimators = params[0]\n",
    "#     max_depth = params[1]\n",
    "#     learning_rate = params[2]\n",
    "#     num_leaves = params[3]\n",
    "#     min_child_samples = params[4]\n",
    "#     subsample = params[5]\n",
    "#     colsample_bytree = params[6]\n",
    "\n",
    "#     print(params, '\\n')\n",
    "\n",
    "#     model_et = ExtraTreesClassifier( learning_rate = learning_rate, num_leaves=num_leaves, n_estimators=n_estimators, max_depth=max_depth, min_child_samples=min_child_samples, subsample=subsample, colsample_bytree=colsample_bytree, n_jobs=-1, random_state=42, subsample_freq=1)\n",
    "#     model_et.fit( X_train, y_train )\n",
    "\n",
    "#     yhat_et = model_et.predict( X_val )\n",
    "\n",
    "#     return -m.f1_score( y_val, yhat_et )\n",
    "\n",
    "# result = gp_minimize( treinar_modelo, search_space, n_calls = 200, n_initial_points = 10, verbose=True, n_jobs=-1, random_state= 42 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.6 KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_space = [(100, 1500), #name = 'n_estimators'), \n",
    "#                 (1, 20), #name = 'max_depth'), \n",
    "#                 (0.001, 0.1, 'log-uniform'),#, name = 'learning_rate'),\n",
    "#                 (2, 128), #name = 'num_leaves'),\n",
    "#                 (1, 100), #name = 'min_child_samples'),\n",
    "#                 (0.05, 1.0), #name = 'subsample'),\n",
    "#                 (0.15, 1.0) #name = 'colsample_bytree')]\n",
    "# ]\n",
    "\n",
    "# def treinar_modelo( params ):\n",
    "#     n_estimators = params[0]\n",
    "#     max_depth = params[1]\n",
    "#     learning_rate = params[2]\n",
    "#     num_leaves = params[3]\n",
    "#     min_child_samples = params[4]\n",
    "#     subsample = params[5]\n",
    "#     colsample_bytree = params[6]\n",
    "\n",
    "#     print(params, '\\n')\n",
    "\n",
    "#     lgbm_model = lgb.LGBMClassifier( learning_rate = learning_rate, num_leaves=num_leaves, n_estimators=n_estimators, max_depth=max_depth, min_child_samples=min_child_samples, subsample=subsample, colsample_bytree=colsample_bytree, n_jobs=-1, random_state=42, subsample_freq=1)\n",
    "#     lgbm_model.fit( X_train, y_train )\n",
    "\n",
    "#     yhat_lgb = lgbm_model.predict( X_val )\n",
    "\n",
    "#     return -m.f1_score( y_val, yhat_lgb )\n",
    "\n",
    "# result = gp_minimize( treinar_modelo, search_space, n_calls = 200, n_initial_points = 10, verbose=True, n_jobs=-1, random_state= 42 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.7 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_space = [(100, 1500), #name = 'n_estimators'), \n",
    "#                 (1, 20), #name = 'max_depth'), \n",
    "#                 (0.001, 0.1, 'log-uniform'),#, name = 'learning_rate'),\n",
    "#                 (2, 128), #name = 'num_leaves'),\n",
    "#                 (1, 100), #name = 'min_child_samples'),\n",
    "#                 (0.05, 1.0), #name = 'subsample'),\n",
    "#                 (0.15, 1.0) #name = 'colsample_bytree')]\n",
    "# ]\n",
    "\n",
    "# def treinar_modelo( params ):\n",
    "#     n_estimators = params[0]\n",
    "#     max_depth = params[1]\n",
    "#     learning_rate = params[2]\n",
    "#     num_leaves = params[3]\n",
    "#     min_child_samples = params[4]\n",
    "#     subsample = params[5]\n",
    "#     colsample_bytree = params[6]\n",
    "\n",
    "#     print(params, '\\n')\n",
    "\n",
    "#     lgbm_model = lgb.LGBMClassifier( learning_rate = learning_rate, num_leaves=num_leaves, n_estimators=n_estimators, max_depth=max_depth, min_child_samples=min_child_samples, subsample=subsample, colsample_bytree=colsample_bytree, n_jobs=-1, random_state=42, subsample_freq=1)\n",
    "#     lgbm_model.fit( X_train, y_train )\n",
    "\n",
    "#     yhat_lgb = lgbm_model.predict( X_val )\n",
    "\n",
    "#     return -m.f1_score( y_val, yhat_lgb )\n",
    "\n",
    "# result = gp_minimize( treinar_modelo, search_space, n_calls = 200, n_initial_points = 10, verbose=True, n_jobs=-1, random_state= 42 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.8 Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_space = [(100, 1500), #name = 'n_estimators'), \n",
    "#                 (1, 20), #name = 'max_depth'), \n",
    "#                 (0.001, 0.1, 'log-uniform'),#, name = 'learning_rate'),\n",
    "#                 (2, 128), #name = 'num_leaves'),\n",
    "#                 (1, 100), #name = 'min_child_samples'),\n",
    "#                 (0.05, 1.0), #name = 'subsample'),\n",
    "#                 (0.15, 1.0) #name = 'colsample_bytree')]\n",
    "# ]\n",
    "\n",
    "# def treinar_modelo( params ):\n",
    "#     n_estimators = params[0]\n",
    "#     max_depth = params[1]\n",
    "#     learning_rate = params[2]\n",
    "#     num_leaves = params[3]\n",
    "#     min_child_samples = params[4]\n",
    "#     subsample = params[5]\n",
    "#     colsample_bytree = params[6]\n",
    "\n",
    "#     print(params, '\\n')\n",
    "\n",
    "#     lgbm_model = lgb.LGBMClassifier( learning_rate = learning_rate, num_leaves=num_leaves, n_estimators=n_estimators, max_depth=max_depth, min_child_samples=min_child_samples, subsample=subsample, colsample_bytree=colsample_bytree, n_jobs=-1, random_state=42, subsample_freq=1)\n",
    "#     lgbm_model.fit( X_train, y_train )\n",
    "\n",
    "#     yhat_lgb = lgbm_model.predict( X_val )\n",
    "\n",
    "#     return -m.f1_score( y_val, yhat_lgb )\n",
    "\n",
    "# result = gp_minimize( treinar_modelo, search_space, n_calls = 200, n_initial_points = 10, verbose=True, n_jobs=-1, random_state= 42 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.9 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_space = [(100, 1500), #name = 'n_estimators'), \n",
    "#                 (1, 20), #name = 'max_depth'), \n",
    "#                 (0.001, 0.1, 'log-uniform'),#, name = 'learning_rate'),\n",
    "#                 (2, 128), #name = 'num_leaves'),\n",
    "#                 (1, 100), #name = 'min_child_samples'),\n",
    "#                 (0.05, 1.0), #name = 'subsample'),\n",
    "#                 (0.15, 1.0) #name = 'colsample_bytree')]\n",
    "# ]\n",
    "\n",
    "# def treinar_modelo( params ):\n",
    "#     n_estimators = params[0]\n",
    "#     max_depth = params[1]\n",
    "#     learning_rate = params[2]\n",
    "#     num_leaves = params[3]\n",
    "#     min_child_samples = params[4]\n",
    "#     subsample = params[5]\n",
    "#     colsample_bytree = params[6]\n",
    "\n",
    "#     print(params, '\\n')\n",
    "\n",
    "#     lgbm_model = lgb.LGBMClassifier( learning_rate = learning_rate, num_leaves=num_leaves, n_estimators=n_estimators, max_depth=max_depth, min_child_samples=min_child_samples, subsample=subsample, colsample_bytree=colsample_bytree, n_jobs=-1, random_state=42, subsample_freq=1)\n",
    "#     lgbm_model.fit( X_train, y_train )\n",
    "\n",
    "#     yhat_lgb = lgbm_model.predict( X_val )\n",
    "\n",
    "#     return -m.f1_score( y_val, yhat_lgb )\n",
    "\n",
    "# result = gp_minimize( treinar_modelo, search_space, n_calls = 200, n_initial_points = 10, verbose=True, n_jobs=-1, random_state= 42 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.10 Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_space = [(100, 1500), #name = 'n_estimators'), \n",
    "#                 (1, 20), #name = 'max_depth'), \n",
    "#                 (0.001, 0.1, 'log-uniform'),#, name = 'learning_rate'),\n",
    "#                 (2, 128), #name = 'num_leaves'),\n",
    "#                 (1, 100), #name = 'min_child_samples'),\n",
    "#                 (0.05, 1.0), #name = 'subsample'),\n",
    "#                 (0.15, 1.0) #name = 'colsample_bytree')]\n",
    "# ]\n",
    "\n",
    "# def treinar_modelo( params ):\n",
    "#     n_estimators = params[0]\n",
    "#     max_depth = params[1]\n",
    "#     learning_rate = params[2]\n",
    "#     num_leaves = params[3]\n",
    "#     min_child_samples = params[4]\n",
    "#     subsample = params[5]\n",
    "#     colsample_bytree = params[6]\n",
    "\n",
    "#     print(params, '\\n')\n",
    "\n",
    "#     lgbm_model = lgb.LGBMClassifier( learning_rate = learning_rate, num_leaves=num_leaves, n_estimators=n_estimators, max_depth=max_depth, min_child_samples=min_child_samples, subsample=subsample, colsample_bytree=colsample_bytree, n_jobs=-1, random_state=42, subsample_freq=1)\n",
    "#     lgbm_model.fit( X_train, y_train )\n",
    "\n",
    "#     yhat_lgb = lgbm_model.predict( X_val )\n",
    "\n",
    "#     return -m.f1_score( y_val, yhat_lgb )\n",
    "\n",
    "# result = gp_minimize( treinar_modelo, search_space, n_calls = 200, n_initial_points = 10, verbose=True, n_jobs=-1, random_state= 42 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5e41ca046b3d9885ca897a71fa607c661abdd256ec5b789ecb59479222986451"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
