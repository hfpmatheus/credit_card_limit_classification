{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.0 IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mathe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import warnings\n",
    "import sweetviz\n",
    "import IPython\n",
    "import pickle\n",
    "\n",
    "import pandas            as pd\n",
    "import numpy             as np\n",
    "import lightgbm          as lgb\n",
    "import xgboost           as xgb\n",
    "import seaborn           as sns\n",
    "\n",
    "from category_encoders       import TargetEncoder\n",
    "from sklearn.preprocessing   import OneHotEncoder\n",
    "from sklearn.ensemble        import ExtraTreesClassifier, RandomForestClassifier, StackingClassifier\n",
    "from scipy                   import stats\n",
    "from unidecode               import unidecode\n",
    "from catboost                import CatBoostClassifier\n",
    "from skopt                   import gp_minimize\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "from sklearn                 import model_selection   as ms\n",
    "from sklearn                 import metrics           as m\n",
    "from matplotlib              import pyplot            as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 AUX FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "def ml_error( model_name, ytest, yhat ):\n",
    "    f1 = m.f1_score( ytest, yhat )\n",
    "\n",
    "    return pd.DataFrame( {'Model name': model_name,\n",
    "                          'F1': f1 }, index=[0] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 READ DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/train.csv')\n",
    "\n",
    "# df_dados_estado = pd.read_csv( \"datasets publicos/Dados Estado Simplificado.csv\" )\n",
    "# df_dados_municipio = pd.read_excel( \"datasets publicos/Dados Município Simplificado.xlsx\", sheet_name=\"Dados\" )\n",
    "# df_pib = pd.read_excel( \"datasets publicos/PIB Municípios.xlsx\" )\n",
    "# df_ibge = pd.read_excel( \"datasets publicos/IBGE.xlsx\", sheet_name=\"Planilha1\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2.2 MERGE PUBLIC DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_dados_estado.rename( columns={ 'População':'populacao_estado','Matrículas':'matriculas_estado',\n",
    "#                                   'Categoria do Quadrante':'categoria_quadrante_estado','Insumos do Ioeb':'insumos_ioeb_estado',\n",
    "#                                   'Ioeb':'ioeb_estado','Resultados do Ioeb':'resultados_ioeb_estado'}, inplace=True)\n",
    "                                  \n",
    "# df_dados_municipio.rename( columns={ 'População':'populacao_cidade','Total de Matrículas':'matriculas_cidade',\n",
    "#                                   'Categoria do Quadrante':'categoria_quadrante_cidade','Insumos do Ioeb':'insumos_ioeb_cidade',\n",
    "#                                   'Ioeb':'ioeb_cidade','Resultados do Ioeb':'resultados_ioeb_cidade','Região':'regiao' }, inplace=True)\n",
    "\n",
    "# for col in df_dados_estado.columns:\n",
    "#     if df_dados_estado[f'{col}'].dtypes != \"int64\" and df_dados_estado[f'{col}'].dtypes != \"float64\":\n",
    "#         df_dados_estado[f'{col}'] = df_dados_estado[f'{col}'].apply(lambda x: x.replace( \",\", \"\" ) if type(x) is not float else x )\n",
    "#         df_dados_estado[f'{col}'] = df_dados_estado[f'{col}'].apply(lambda x: x.replace( \".\", \"\" ) if type(x) is not float else x )\n",
    "\n",
    "# for col in df_dados_municipio.columns:\n",
    "#     if df_dados_municipio[f'{col}'].dtypes != \"int64\" and type(df_dados_municipio[f'{col}']) != \"float64\":\n",
    "#         df_dados_municipio[f'{col}'] = df_dados_municipio[f'{col}'].apply(lambda x: x.replace( \",\", \"\" ) if type(x) is not float else x )\n",
    "#         df_dados_municipio[f'{col}'] = df_dados_municipio[f'{col}'].apply(lambda x: x.replace( \".\", \"\" ) if type(x) is not float else x )\n",
    "\n",
    "# # merge df users com df dados estado\n",
    "# df_dados_estado['Estado'] = df_dados_estado['Estado'].apply( lambda x: unidecode(x).upper() )\n",
    "# df['region'] = df['region'].apply( lambda x: unidecode(x).upper() if type(x) is not float else x )\n",
    "\n",
    "# df = df.merge( df_dados_estado, how='left', left_on='region', right_on='Estado' )\n",
    "# df.drop( columns=['Estado','Ano do Ioeb','Código da UF','Unidade da Federação','Região'], inplace=True )\n",
    "\n",
    "# # merge df users com df dados municipio\n",
    "# df_dados_municipio['Nome do Município'] = df_dados_municipio['Nome do Município'].apply( lambda x: unidecode(x).upper() )\n",
    "# df['city'] = df['city'].apply( lambda x: unidecode(x).upper() if type(x) is not float else x )\n",
    "\n",
    "# df = df.merge( df_dados_municipio, how='left', left_on='city', right_on='Nome do Município' )\n",
    "# df.drop( columns=['Código do Município','Código da UF','Unidade da Federação','Nome do Município','Ano do Ioeb'], inplace=True )\n",
    "\n",
    "# features_to_float = ['ioeb_estado', 'insumos_ioeb_estado', 'resultados_ioeb_estado', 'populacao_estado', \n",
    "# 'ioeb_cidade', 'insumos_ioeb_cidade', 'resultados_ioeb_cidade', 'matriculas_cidade', 'populacao_cidade']\n",
    "# df[features_to_float] = df[features_to_float].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pib['Município'] = df_pib['Município'].apply( lambda x: x.split('(')[0] )\n",
    "# df_pib['Município'] = df_pib['Município'].apply( lambda x: unidecode(x).upper().strip() )\n",
    "\n",
    "# df = df.merge( df_pib, how='left', left_on='city', right_on='Município' )\n",
    "# df.drop( columns=['Município'], inplace=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ibge = df_ibge[['Município','IDHM','IDHM_E','IDHM_L','IDHM_R','I_ESCOLARIDADE','I_FREQ_PROP','TRABPUB','RENOCUP','GINI','T_FLSUPER',\n",
    "# 'T_ANALF18M','E_ANOSESTUDO','ESPVIDA']]\n",
    "# df_ibge['Município'] = df_ibge['Município'].apply( lambda x: unidecode(x).upper().strip() )\n",
    "\n",
    "# df = df.merge( df_ibge, how='left', left_on='city', right_on='Município' )\n",
    "# df.drop( columns=['Município'], inplace=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 DATA DESCRIPTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df users rows: 9500\n",
      "df users columns: 17\n"
     ]
    }
   ],
   "source": [
    "print( f\"df users rows: {df.shape[0]}\" )\n",
    "print( f\"df users columns: {df.shape[1]}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_cliente</th>\n",
       "      <th>idade</th>\n",
       "      <th>saldo_atual</th>\n",
       "      <th>divida_atual</th>\n",
       "      <th>renda_anual</th>\n",
       "      <th>valor_em_investimentos</th>\n",
       "      <th>taxa_utilizacao_credito</th>\n",
       "      <th>num_emprestimos</th>\n",
       "      <th>num_contas_bancarias</th>\n",
       "      <th>num_cartoes_credito</th>\n",
       "      <th>dias_atraso_dt_venc</th>\n",
       "      <th>num_pgtos_atrasados</th>\n",
       "      <th>num_consultas_credito</th>\n",
       "      <th>taxa_juros</th>\n",
       "      <th>investe_exterior</th>\n",
       "      <th>pessoa_polit_exp</th>\n",
       "      <th>limite_adicional</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1767</td>\n",
       "      <td>21</td>\n",
       "      <td>278.172008</td>\n",
       "      <td>2577.05</td>\n",
       "      <td>24196.89636</td>\n",
       "      <td>104.306544</td>\n",
       "      <td>31.038763</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Negar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11920</td>\n",
       "      <td>40</td>\n",
       "      <td>268.874152</td>\n",
       "      <td>2465.39</td>\n",
       "      <td>19227.37796</td>\n",
       "      <td>69.858778</td>\n",
       "      <td>36.917093</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Negar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8910</td>\n",
       "      <td>36</td>\n",
       "      <td>446.643127</td>\n",
       "      <td>1055.29</td>\n",
       "      <td>42822.28223</td>\n",
       "      <td>134.201478</td>\n",
       "      <td>34.561714</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>Sim</td>\n",
       "      <td>Não</td>\n",
       "      <td>Negar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4964</td>\n",
       "      <td>58</td>\n",
       "      <td>321.141267</td>\n",
       "      <td>703.05</td>\n",
       "      <td>51786.82600</td>\n",
       "      <td>297.350067</td>\n",
       "      <td>31.493561</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Sim</td>\n",
       "      <td>Não</td>\n",
       "      <td>Negar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10100</td>\n",
       "      <td>35</td>\n",
       "      <td>428.716114</td>\n",
       "      <td>891.29</td>\n",
       "      <td>44626.85346</td>\n",
       "      <td>134.201478</td>\n",
       "      <td>28.028887</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>Sim</td>\n",
       "      <td>Não</td>\n",
       "      <td>Negar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_cliente  idade  saldo_atual  divida_atual  renda_anual  \\\n",
       "0        1767     21   278.172008       2577.05  24196.89636   \n",
       "1       11920     40   268.874152       2465.39  19227.37796   \n",
       "2        8910     36   446.643127       1055.29  42822.28223   \n",
       "3        4964     58   321.141267        703.05  51786.82600   \n",
       "4       10100     35   428.716114        891.29  44626.85346   \n",
       "\n",
       "   valor_em_investimentos  taxa_utilizacao_credito  num_emprestimos  \\\n",
       "0              104.306544                31.038763                6   \n",
       "1               69.858778                36.917093                5   \n",
       "2              134.201478                34.561714                0   \n",
       "3              297.350067                31.493561                0   \n",
       "4              134.201478                28.028887                2   \n",
       "\n",
       "   num_contas_bancarias  num_cartoes_credito  dias_atraso_dt_venc  \\\n",
       "0                     5                    7                   21   \n",
       "1                     8                    5                   40   \n",
       "2                     3                    6                   26   \n",
       "3                     3                    7                   12   \n",
       "4                     8                    7                   24   \n",
       "\n",
       "   num_pgtos_atrasados  num_consultas_credito  taxa_juros investe_exterior  \\\n",
       "0                   14                      9          15              Não   \n",
       "1                   23                     10          18              Não   \n",
       "2                   13                      3          15              Sim   \n",
       "3                    7                      2           1              Sim   \n",
       "4                   10                      8          20              Sim   \n",
       "\n",
       "  pessoa_polit_exp limite_adicional  \n",
       "0              Não            Negar  \n",
       "1              Não            Negar  \n",
       "2              Não            Negar  \n",
       "3              Não            Negar  \n",
       "4              Não            Negar  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Check NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id_cliente                 0\n",
       "idade                      0\n",
       "saldo_atual                0\n",
       "divida_atual               0\n",
       "renda_anual                0\n",
       "valor_em_investimentos     0\n",
       "taxa_utilizacao_credito    0\n",
       "num_emprestimos            0\n",
       "num_contas_bancarias       0\n",
       "num_cartoes_credito        0\n",
       "dias_atraso_dt_venc        0\n",
       "num_pgtos_atrasados        0\n",
       "num_consultas_credito      0\n",
       "taxa_juros                 0\n",
       "investe_exterior           0\n",
       "pessoa_polit_exp           0\n",
       "limite_adicional           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Fill NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Change Dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['data'] = pd.to_datetime( df['data'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # year\n",
    "# df2['year'] = df2['created_at'].dt.year\n",
    "\n",
    "# # month\n",
    "# df2['month'] = df2['created_at'].dt.month\n",
    "\n",
    "# # day\n",
    "# df2['day'] = df2['created_at'].dt.day\n",
    "\n",
    "# # week of year \n",
    "# df2['week_of_year'] = df2['created_at'].dt.isocalendar().week\n",
    "\n",
    "# # week of year \n",
    "# df2['day_of_week'] = df2['created_at'].dt.weekday\n",
    "\n",
    "# # hour\n",
    "# df2['hour'] = df2['created_at'].dt.hour\n",
    "\n",
    "# # minute\n",
    "# df2['minute'] = df2['created_at'].dt.minute\n",
    "\n",
    "# # second\n",
    "# df2['second'] = df2['created_at'].dt.second\n",
    "\n",
    "# # nivel de concentracao\n",
    "# df2['concentracao'] = df2['row'].apply( lambda x: 'pomodoro1' if x <=10 else \n",
    "#                                                               'pomodoro2' if x > 10 and x <= 20 else\n",
    "#                                                               'pomodoro3' if x > 20 and x <= 30 else\n",
    "#                                                               'pomodoro4' if x > 30 and x <= 40 else \n",
    "#                                                               'pomodoro5' if x > 40 and x <= 50 else \n",
    "#                                                               'pomodoro6' if x > 50 and x <= 60 else \n",
    "#                                                               'pomodoro7' if x > 60 and x <= 70 else \n",
    "#                                                               'pomodoro8' if x > 70 and x <= 80 else \n",
    "#                                                               'pomodoro9' if x > 80 and x <= 90 else \n",
    "#                                                               'pomodoro10' )\n",
    "\n",
    "# # letras_recorrentes\n",
    "# letras_recorrentes = ['A','E']\n",
    "# df2['letras_recorrentes'] = df2['right_answer'].apply( lambda x: 'recorrente' if x in letras_recorrentes else 'nao recorrente'  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 DATA FILTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0 EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3.copy()\n",
    "\n",
    "# sweetviz report\n",
    "# report = sweetviz.analyze( df, \"limite_adicional\" )\n",
    "# report.show_html()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.0 DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df3.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limite adicional\n",
    "df5['limite_adicional'] = df5['limite_adicional'].apply( lambda x: 0 if x == 'Negar' else 1 )\n",
    "\n",
    "# target encoder\n",
    "te = TargetEncoder()\n",
    "\n",
    "df5['investe_exterior'] = te.fit_transform( df5['investe_exterior'], df5['limite_adicional'] )\n",
    "df5['pessoa_polit_exp'] = te.fit_transform( df5['pessoa_polit_exp'], df5['limite_adicional'] )\n",
    "\n",
    "# # natural variable transformation\n",
    "# # day\n",
    "# df5['day_sin'] = df5['day'].apply( lambda x: np.sin( x * ( 2 * np.pi/30 ) ) )\n",
    "# df5['day_cos'] = df5['day'].apply( lambda x: np.cos( x * ( 2 * np.pi/30 ) ) )\n",
    "\n",
    "# # day of week\n",
    "# df5['day_of_week_sin'] = df5['day_of_week'].apply( lambda x: np.sin( x * ( 2 * np.pi/7 ) ) )\n",
    "# df5['day_of_week_cos'] = df5['day_of_week'].apply( lambda x: np.cos( x * ( 2 * np.pi/7 ) ) )\n",
    "\n",
    "# # month\n",
    "# df5['month_sin'] = df5['month'].apply( lambda x: np.sin( x * ( 2 * np.pi/12 ) ) )\n",
    "# df5['month_cos'] = df5['month'].apply( lambda x: np.cos( x * ( 2 * np.pi/12 ) ) )\n",
    "\n",
    "# # week of year\n",
    "# df5['week_of_year_sin'] = df5['week_of_year'].apply( lambda x: np.sin( x * ( 2 * np.pi/52 ) ) )\n",
    "# df5['week_of_year_cos'] = df5['week_of_year'].apply( lambda x: np.cos( x * ( 2 * np.pi/52 ) ) )\n",
    "\n",
    "# # hour\n",
    "# df5['hour_sin'] = df5['hour'].apply( lambda x: np.sin( x * ( 2 * np.pi/24 ) ) )\n",
    "# df5['hour_cos'] = df5['hour'].apply( lambda x: np.cos( x * ( 2 * np.pi/24 ) ) )\n",
    "\n",
    "# # quarter\n",
    "# df5['minute_sin'] = df5['minute'].apply( lambda x: np.sin( x * ( 2 * np.pi/60 ) ) )\n",
    "# df5['minute_cos'] = df5['minute'].apply( lambda x: np.cos( x * ( 2 * np.pi/60 ) ) )\n",
    "\n",
    "# # quarter\n",
    "# df5['second_sin'] = df5['second'].apply( lambda x: np.sin( x * ( 2 * np.pi/60 ) ) )\n",
    "# df5['second_cos'] = df5['second'].apply( lambda x: np.cos( x * ( 2 * np.pi/60 ) ) )\n",
    "\n",
    "# df5.drop( columns=['day','day_of_week','month','week_of_year','year','hour'], inplace=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.0 FEATURE SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model\n",
    "# forest = ExtraTreesClassifier( n_jobs=-1 )\n",
    "\n",
    "# # training\n",
    "# X = df5.copy()\n",
    "# Y = df5['limite_adicional'].values\n",
    "\n",
    "# x_train_fselection, x_val, y_train_fselection, y_val = ms.train_test_split( X, Y, test_size=0.5, random_state=42 )\n",
    "\n",
    "# forest.fit( x_train_fselection, y_train_fselection )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importances = forest.feature_importances_\n",
    "# std = np.std( [tree.feature_importances_ for tree in forest.estimators_], axis=0 )\n",
    "# indices = np.argsort( importances )[::-1]\n",
    "\n",
    "# # print the feature ranking\n",
    "# df = pd.DataFrame()\n",
    "\n",
    "# print( 'Feature Ranking:\\n' )\n",
    "# for i, j in zip( x_train_fselection,forest.feature_importances_ ):\n",
    "#     aux = pd.DataFrame( {'feature': i, 'importance': j}, index=[0] )\n",
    "#     df = pd.concat( [df, aux], axis=0 )\n",
    "    \n",
    "# print( df.sort_values( 'importance', ascending=False ) ) \n",
    "\n",
    "# # plot the impurity-based feature importances of the forest\n",
    "# plt.figure(figsize=(10,5))\n",
    "# plt.title( 'Feature importances' )\n",
    "# plt.bar( range( x_train_fselection.shape[1] ), importances[indices], color='r', yerr=std[indices], align='center' )\n",
    "# plt.xticks( range(x_train_fselection.shape[1]), indices )\n",
    "# plt.xlim( [-1, x_train_fselection.shape[1]] )\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.0 MACHINE LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_selected = []\n",
    "\n",
    "X = df5.drop(columns=['limite_adicional'])\n",
    "Y = df5['limite_adicional'].copy()\n",
    "\n",
    "X_train, X_val, y_train, y_val = ms.train_test_split( X, Y, test_size=0.2, random_state=42 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model name</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.543119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model name        F1\n",
       "0   LightGBM  0.543119"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model\n",
    "model_lgb = lgb.LGBMClassifier( n_jobs=-1 ).fit( X_train, y_train )\n",
    "\n",
    "# prediction\n",
    "yhat_lgb = model_lgb.predict( X_val )\n",
    "\n",
    "# performance\n",
    "model_lgb_results = ml_error( 'LightGBM',  y_val, yhat_lgb )\n",
    "model_lgb_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.1 Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # cross validation\n",
    "# kfold = KFold(n_splits=7, random_state=1, shuffle=True)\n",
    "# cv = cross_val_score(model_lgb, X, Y, scoring='f1', cv=kfold, n_jobs=-1, error_score='raise' )\n",
    "# print( \"{} +/- {}\" ).format( np.mean(cv), np.std(cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model\n",
    "# model_xgb = xgb.XGBClassifier( n_jobs=-1 ).fit( X_train, y_train )\n",
    "\n",
    "# # prediction\n",
    "# yhat_xgb = model_xgb.predict( X_val )\n",
    "\n",
    "# # performance\n",
    "# model_xgb_results = ml_error( 'XGBoost',  y_val, yhat_xgb )\n",
    "# model_xgb_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.1 Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model\n",
    "# model_cb = CatBoostClassifier().fit( X_train, y_train )\n",
    "\n",
    "# # prediction\n",
    "# yhat_cb = model_cb.predict( X_val )\n",
    "\n",
    "# # performance\n",
    "# model_cb_results = ml_error( 'CatBoost',  y_val, yhat_cb)\n",
    "# model_cb_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.1 Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4 Stacking Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimators_list = [ ('lgbm', model_lgb), ('xgboost', model_xgb), ('catboost', model_cb) ]\n",
    "\n",
    "# # Build stack model\n",
    "# stack_model = StackingClassifier( estimators = estimators_list, n_jobs=-1, verbose=True ).fit( X_train, y_train )\n",
    "\n",
    "# # prediction\n",
    "# yhat_stack = stack_model.predict( X_val )\n",
    "\n",
    "# # performance\n",
    "# stack_model_results = ml_error( 'Stacking', y_val, yhat_stack )\n",
    "# stack_model_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.0 Bayesian Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 LGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.1 Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_space = [(100, 1500), #name = 'n_estimators'), \n",
    "#                 (1, 20), #name = 'max_depth'), \n",
    "#                 (0.001, 0.1, 'log-uniform'),#, name = 'learning_rate'),\n",
    "#                 (2, 128), #name = 'num_leaves'),\n",
    "#                 (1, 100), #name = 'min_child_samples'),\n",
    "#                 (0.05, 1.0), #name = 'subsample'),\n",
    "#                 (0.15, 1.0) #name = 'colsample_bytree')]\n",
    "# ]\n",
    "\n",
    "# def treinar_modelo( params ):\n",
    "#     n_estimators = params[0]\n",
    "#     max_depth = params[1]\n",
    "#     learning_rate = params[2]\n",
    "#     num_leaves = params[3]\n",
    "#     min_child_samples = params[4]\n",
    "#     subsample = params[5]\n",
    "#     colsample_bytree = params[6]\n",
    "\n",
    "#     print(params)\n",
    "\n",
    "#     lgbm_model = lgb.LGBMClassifier( learning_rate = learning_rate, num_leaves=num_leaves, n_estimators=n_estimators, max_depth=max_depth, min_child_samples=min_child_samples, subsample=subsample, colsample_bytree=colsample_bytree, n_jobs=-1, random_state=42, subsample_freq=1)\n",
    "#     lgbm_model.fit( X_train, y_train )\n",
    "\n",
    "#     yhat_lgb = lgbm_model.predict( X_val )\n",
    "\n",
    "#     return -m.f1_score( y_val, yhat_lgb )\n",
    "\n",
    "# result = gp_minimize( treinar_modelo, search_space, n_calls = 200, n_initial_points = 10, verbose=True, n_jobs=-1, random_state= 42 )\n",
    "# print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.2 Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGBM CV BAYESIAN SEARCH\n",
    "\n",
    "# search_space = [(100, 1500), #name = 'n_estimators'), \n",
    "#                 (1, 20), #name = 'max_depth'), \n",
    "#                 (0.001, 0.1, 'log-uniform'),#, name = 'learning_rate'),\n",
    "#                 (2, 128), #name = 'num_leaves'),\n",
    "#                 (1, 100), #name = 'min_child_samples'),\n",
    "#                 (0.05, 1.0), #name = 'subsample'),\n",
    "#                 (0.15, 1.0) #name = 'colsample_bytree')]\n",
    "# ]\n",
    "\n",
    "# def treinar_modelo( params ):\n",
    "#     n_estimators = params[0]\n",
    "#     max_depth = params[1]\n",
    "#     learning_rate = params[2]\n",
    "#     num_leaves = params[3]\n",
    "#     min_child_samples = params[4]\n",
    "#     subsample = params[5]\n",
    "#     colsample_bytree = params[6]\n",
    "\n",
    "#     print(params, '\\n' )\n",
    "\n",
    "#     lgbm_model = lgb.LGBMClassifier( learning_rate = learning_rate, num_leaves=num_leaves, n_estimators=n_estimators, max_depth=max_depth, min_child_samples=min_child_samples, subsample=subsample, colsample_bytree=colsample_bytree, n_jobs=-1, random_state=42, subsample_freq=1)\n",
    "#     kfold = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "#     cv = cross_val_score(lgbm_model, X, Y, scoring='f1', cv=kfold, n_jobs=-1)\n",
    "\n",
    "#     return -np.mean(cv)\n",
    "\n",
    "# result = gp_minimize( treinar_modelo, search_space, n_calls = 200, n_initial_points = 10, verbose=True, n_jobs=-1, random_state= 42 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.1 Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_space = [(6, 10), #depth\n",
    "#                 (0.01, 0.1), #learning rate\n",
    "#                 (100, 200), #iterations\n",
    "# ]\n",
    "\n",
    "# def treinar_modelo( params ):\n",
    "#     depth = params[0]\n",
    "#     learning_rate = params[1]\n",
    "#     iterations = params[2]\n",
    "\n",
    "#     print(params, '\\n' )\n",
    "\n",
    "#     catboost_model = CatBoostClassifier( depth = depth, learning_rate=learning_rate, iterations=iterations, verbose=False )\n",
    "#     catboost_model.fit( X_train, y_train )\n",
    "\n",
    "#     yhat_catboost = catboost_model.predict( X_val )\n",
    "\n",
    "#     return -m.f1_score( y_val, yhat_catboost )\n",
    "\n",
    "# result = gp_minimize( treinar_modelo, search_space, n_calls = 100, n_initial_points = 10, verbose=True, n_jobs=-1, random_state= 42 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5e41ca046b3d9885ca897a71fa607c661abdd256ec5b789ecb59479222986451"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
