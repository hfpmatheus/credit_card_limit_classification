{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import warnings\n",
    "import sweetviz\n",
    "import IPython\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "import pandas            as pd\n",
    "import numpy             as np\n",
    "import lightgbm          as lgb\n",
    "import xgboost           as xgb\n",
    "import seaborn           as sns\n",
    "\n",
    "from category_encoders       import TargetEncoder\n",
    "from sklearn.preprocessing   import OneHotEncoder\n",
    "from sklearn.ensemble        import ExtraTreesClassifier, RandomForestClassifier, StackingClassifier\n",
    "from sklearn.linear_model    import LogisticRegression\n",
    "from sklearn.neighbors       import KNeighborsClassifier\n",
    "from sklearn.naive_bayes     import GaussianNB\n",
    "from scipy                   import stats\n",
    "from unidecode               import unidecode\n",
    "from catboost                import CatBoostClassifier\n",
    "from skopt                   import gp_minimize\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from imblearn                import over_sampling, under_sampling\n",
    "from sklearn                 import svm\n",
    "from sklearn.preprocessing   import RobustScaler, MinMaxScaler\n",
    "from sklearn.tree            import DecisionTreeClassifier\n",
    "from sklearn.neural_network  import MLPClassifier\n",
    "\n",
    "from sklearn                 import model_selection   as ms\n",
    "from sklearn                 import metrics           as m\n",
    "from matplotlib              import pyplot            as plt\n",
    "from imblearn                import combine           as co\n",
    "from sklearn                 import manifold          as mn\n",
    "from sklearn                 import cluster           as c\n",
    "from yellowbrick.cluster     import KElbowVisualizer, SilhouetteVisualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mathe\\AppData\\Local\\Temp\\ipykernel_43208\\437504961.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['num_contas_bancarias'][i] = 1\n"
     ]
    }
   ],
   "source": [
    "df2 = df.copy()\n",
    "\n",
    "for i in range(len( df2)):\n",
    "    if df2['num_contas_bancarias'][i] == 0:\n",
    "        df2['num_contas_bancarias'][i] = 1\n",
    "\n",
    "df2['num_contas_bancarias'] = df2['num_contas_bancarias'].apply( lambda x: int(str(x)[:2]) if x>50 else x )\n",
    "\n",
    "df2['idade'] = df2['idade'].apply( lambda x: int(str(x)[:2]) if x>100 else x )\n",
    "df2['idade'] = df2['idade'].apply( lambda x: 18 if x < 18 else x )\n",
    "\n",
    "df2['taxa_juros'] = df2['taxa_juros'].apply( lambda x: int(str(x)[:2]) if x>100 else x )\n",
    "df2['taxa_juros'] = df2['taxa_juros'].apply( lambda x: x/100 )\n",
    "\n",
    "mediana_cartao = df2['num_cartoes_credito'].median()\n",
    "df2['num_cartoes_credito'] = df2['num_cartoes_credito'].apply( lambda x: mediana_cartao if x>100 else x )\n",
    "\n",
    "df2['num_emprestimos'] = df2['num_emprestimos'].apply( lambda x: int(str(x)[:2]) if x>100 else x )\n",
    "\n",
    "mediana_pg = df2['num_pgtos_atrasados'].median()\n",
    "df2['num_pgtos_atrasados'] = df2['num_pgtos_atrasados'].apply( lambda x: mediana_pg if x>100 else x )\n",
    "\n",
    "df2['num_consultas_credito'] = df2['num_consultas_credito'].apply( lambda x: int(str(x)[:2]) if x>100 else x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.copy()\n",
    "\n",
    "df3['porcentagem_investido'] = df3.apply( lambda x: x.valor_em_investimentos / x.renda_anual, axis=1 )\n",
    "\n",
    "df3['renda_anual'] = df3['renda_anual'].apply( lambda x: x/12 )\n",
    "\n",
    "df3['faixa_num_emprestimos'] = df3['num_emprestimos'].apply( lambda x: '0' if x <= 0 else \n",
    "                                                                       '1 - 3' if x >= 1 and x <= 3 else\n",
    "                                                                       '4 - 6' if x >= 4 and x <= 6 else\n",
    "                                                                       '6 - 9' if x >= 6 and x <= 9 else\n",
    "                                                                       '10 +' if x > 10 else x)\n",
    "\n",
    "df3['porcentagem_divida'] = df3.apply( lambda x: x['renda_anual'] / x['divida_atual'], axis=1 )\n",
    "df3['atraso_max_34'] = df3['num_pgtos_atrasados'].apply( lambda x: 1 if x <=34 else 0 )\n",
    "df3['nenhum_dia_de_atraso'] = df3['dias_atraso_dt_venc'].apply( lambda x: 1 if x <=0 else 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df3.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "idade_rescaling = pickle.load( open( 'encoders/idade_scaler', 'rb' ) )\n",
    "df5['idade'] = idade_rescaling.transform(df5[['idade']].values)\n",
    "\n",
    "porcentagem_divida_rescaling = pickle.load( open( 'encoders/porcentagem_divida_scaler', 'rb' ) )\n",
    "df5['porcentagem_divida'] = porcentagem_divida_rescaling.transform(df5[['porcentagem_divida']].values)\n",
    "\n",
    "saldo_atual_rescaling = pickle.load( open( 'encoders/saldo_atual_scaler', 'rb' ) )\n",
    "df5['saldo_atual'] = saldo_atual_rescaling.transform(df5[['saldo_atual']].values)\n",
    "\n",
    "divida_atual_rescaling = pickle.load( open( 'encoders/divida_atual_scaler', 'rb' ) )\n",
    "df5['divida_atual'] = divida_atual_rescaling.transform(df5[['divida_atual']].values)\n",
    "\n",
    "renda_anual_rescaling = pickle.load( open( 'encoders/renda_anual_scaler', 'rb' ) )\n",
    "df5['renda_anual'] = renda_anual_rescaling.transform(df5[['renda_anual']].values)\n",
    "\n",
    "valor_em_investimentos_rescaling = pickle.load( open( 'encoders/valor_em_investimentos_scaler', 'rb' ) )\n",
    "df5['valor_em_investimentos'] = valor_em_investimentos_rescaling.transform(df5[['valor_em_investimentos']].values)\n",
    "\n",
    "taxa_utilizacao_credito_rescaling = pickle.load( open( 'encoders/taxa_utilizacao_credito_scaler', 'rb' ) )\n",
    "df5['taxa_utilizacao_credito'] = taxa_utilizacao_credito_rescaling.transform(df5[['taxa_utilizacao_credito']].values)\n",
    "\n",
    "num_emprestimos_rescaling = pickle.load( open( 'encoders/num_emprestimos_scaler', 'rb' ) )\n",
    "df5['num_emprestimos'] = num_emprestimos_rescaling.transform(df5[['num_emprestimos']].values)\n",
    "\n",
    "num_contas_bancarias_rescaling = pickle.load( open( 'encoders/num_contas_bancarias_scaler', 'rb' ) )\n",
    "df5['num_contas_bancarias'] = num_contas_bancarias_rescaling.transform(df5[['num_contas_bancarias']].values)\n",
    "\n",
    "num_cartoes_credito_rescaling = pickle.load( open( 'encoders/num_cartoes_credito_scaler', 'rb' ) )\n",
    "df5['num_cartoes_credito'] = num_cartoes_credito_rescaling.transform(df5[['num_cartoes_credito']].values)\n",
    "\n",
    "dias_atraso_dt_venc_rescaling = pickle.load( open( 'encoders/dias_atraso_dt_venc_scaler', 'rb' ) )\n",
    "df5['dias_atraso_dt_venc'] = dias_atraso_dt_venc_rescaling.transform(df5[['dias_atraso_dt_venc']].values)\n",
    "\n",
    "num_pgtos_atrasados_rescaling = pickle.load( open( 'encoders/num_pgtos_atrasados_scaler', 'rb' ) )\n",
    "df5['num_pgtos_atrasados'] = num_pgtos_atrasados_rescaling.transform(df5[['num_pgtos_atrasados']].values)\n",
    "\n",
    "num_consultas_credito_rescaling = pickle.load( open( 'encoders/num_consultas_credito_scaler', 'rb' ) )\n",
    "df5['num_consultas_credito'] = num_consultas_credito_rescaling.transform(df5[['num_consultas_credito']].values)\n",
    "\n",
    "taxa_juros_rescaling = pickle.load( open( 'encoders/taxa_juros_scaler', 'rb' ) )\n",
    "df5['taxa_juros'] = taxa_juros_rescaling.transform(df5[['taxa_juros']].values)\n",
    "\n",
    "porcentagem_investido_rescaling = pickle.load( open( 'encoders/porcentagem_investido_scaler', 'rb' ) )\n",
    "df5['porcentagem_investido'] = porcentagem_investido_rescaling.transform(df5[['porcentagem_investido']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Encoder\n",
    "investe_exterior_encoding = pickle.load( open( 'encoders/investe_exterior_encoding', 'rb' ) )\n",
    "df5['investe_exterior'] = investe_exterior_encoding.transform(df5['investe_exterior'])\n",
    "\n",
    "pessoa_polit_exp_encoding = pickle.load( open( 'encoders/pessoa_polit_exp_encoding', 'rb' ) )\n",
    "df5['pessoa_polit_exp'] = pessoa_polit_exp_encoding.transform(df5['pessoa_polit_exp'])\n",
    "\n",
    "faixa_num_emprestimos_encoding = pickle.load( open( 'encoders/faixa_num_emprestimos_encoding', 'rb' ) )\n",
    "df5['faixa_num_emprestimos'] = faixa_num_emprestimos_encoding.transform(df5['faixa_num_emprestimos'])\n",
    "\n",
    "df5.drop( columns =['id_cliente'],inplace=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model\n",
    "model = pickle.load( open( 'model/model_stack_final.pkl' , 'rb' ) )\n",
    "\n",
    "# prediction\n",
    "pred = model.predict( df5 )\n",
    "        \n",
    "# join pred into the original data\n",
    "df3['limite_adicional'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3[['id_cliente','limite_adicional']]\n",
    "df3['limite_adicional'] = df3['limite_adicional'].apply( lambda x: 'Negar' if x == 0 else 'Conceder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_csv('submissions/ultimo_submit2222222222.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Target Encoder\n",
    "# versao_encoding = pickle.load( open( 'encoders/versao_encoding', 'rb' ) )\n",
    "# df5['versao'] = versao_encoding.transform(df5['versao'])\n",
    "\n",
    "# # One Hot Encoder\n",
    "# combustivel_encoding = pickle.load( open( 'encoders/combustivel_encoding', 'rb' ) )\n",
    "# df_combustivel = pd.DataFrame(combustivel_encoding.transform(df5[['combustivel']]).toarray())\n",
    "# df_combustivel.columns = combustivel_encoding.get_feature_names_out()\n",
    "# df5 = df5.join(df_combustivel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load trained model\n",
    "# model = pickle.load( open( 'model/mobility_cars_lgb.pkl' , 'rb' ) )\n",
    "\n",
    "# # prediction\n",
    "# pred = model.predict( df5 )\n",
    "        \n",
    "# # join pred into the original data\n",
    "# df_submission['prediction'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission = df_submission[['ID','prediction']]\n",
    "# Submission.to_csv('submissions/Submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5e41ca046b3d9885ca897a71fa607c661abdd256ec5b789ecb59479222986451"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
